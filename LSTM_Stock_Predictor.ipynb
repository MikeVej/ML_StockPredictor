{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Market Predictor (LSTM) (**Work in Progress**)\n",
    "---\n",
    "Howdy!\n",
    "\n",
    "### **Introduction:**\n",
    "\n",
    "For this project, I am using a Long Short-Term Memory Neural Network Model to predict stock price since this technique is good at noticing patterns in sequential data which can help make future predictions.\n",
    "\n",
    "\n",
    "\n",
    "#### **Project Framework:**\n",
    "\n",
    "**Data Obtaining:** Obtain stock price data by grabbing it fromm YahooFinance. To make this simple, I will only do predictions on one stock at a time (Starting With JP Morgan - JPM)\n",
    "\n",
    "**Data Cleaning:** The data will then be cleaned getting rid of any missing values (not viable to fill nulls with mean). Clean the date data of the stock so that it can be put through the model\n",
    "\n",
    "**Choose Model:** LSTM since we can include many variables that effect stock price. Not including corporate news sadly.\n",
    "\n",
    "**Set Model Paramters:** This is still a machine learning technique so choosing the right paramters will be important when I train the model.\n",
    "\n",
    "**Train the Model:** Run model with the stock data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras\n",
    "#!pip install tensorflow\n",
    "#!pip install yfinance --upgrade --no-cache-dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()  # Set the seaborn style\n",
    "\n",
    "# -- Sklearn --\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# -- Date Libraries\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# -- Keras --\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# -- Yahoo Finance --\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data from Yahoo Finance (In progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'address1': '383 Madison Avenue', 'city': 'New York', 'state': 'NY', 'zip': '10179', 'country': 'United States', 'phone': '212 270 6000', 'website': 'https://www.jpmorganchase.com', 'industry': 'Banks - Diversified', 'industryKey': 'banks-diversified', 'industryDisp': 'Banks - Diversified', 'sector': 'Financial Services', 'sectorKey': 'financial-services', 'sectorDisp': 'Financial Services', 'longBusinessSummary': 'JPMorgan Chase & Co. operates as a financial services company worldwide. It operates through four segments: Consumer & Community Banking (CCB), Corporate & Investment Bank (CIB), Commercial Banking (CB), and Asset & Wealth Management (AWM). The CCB segment offers deposit, investment and lending products, cash management, and payments and services; mortgage origination and servicing activities; residential mortgages and home equity loans; and credit cards, auto loans, leases, and travel services to consumers and small businesses through bank branches, ATMs, and digital and telephone banking. The CIB segment provides investment banking products and services, including corporate strategy and structure advisory, and equity and debt market capital-raising services, as well as loan origination and syndication; payments; and cash and derivative instruments, risk management solutions, prime brokerage, and research. This segment also offers securities services, including custody, fund accounting and administration, and securities lending products for asset managers, insurance companies, and public and private investment funds. The CB segment provides financial solutions, including lending, payments, investment banking, and asset management to small and midsized companies, local governments, nonprofit clients, and large corporations, as well as investors, developers, and owners of multifamily, office, retail, industrial, and affordable housing properties. The AWM segment offers multi-asset investment management solutions in equities, fixed income, alternatives, and money market funds to institutional clients and retail investors; and retirement products and services, brokerage, custody, estate planning, lending, deposits, and investment management products to high net worth clients. JPMorgan Chase & Co. was founded in 1799 and is headquartered in New York, New York.', 'fullTimeEmployees': 309926, 'companyOfficers': [{'maxAge': 1, 'name': 'Mr. James  Dimon', 'age': 67, 'title': 'Chairman & CEO', 'yearBorn': 1956, 'fiscalYear': 2022, 'totalPay': 6818729, 'exercisedValue': 0, 'unexercisedValue': 0}, {'maxAge': 1, 'name': 'Mr. Daniel Eduardo Pinto', 'age': 60, 'title': 'President & COO', 'yearBorn': 1963, 'fiscalYear': 2022, 'totalPay': 7162401, 'exercisedValue': 7226498, 'unexercisedValue': 0}, {'maxAge': 1, 'name': 'Mr. Jeremy  Barnum', 'age': 50, 'title': 'Executive VP & CFO', 'yearBorn': 1973, 'fiscalYear': 2022, 'totalPay': 5255000, 'exercisedValue': 0, 'unexercisedValue': 0}, {'maxAge': 1, 'name': 'Ms. Mary Callahan Erdoes', 'age': 56, 'title': 'Chief Executive Officer of Asset & Wealth Management', 'yearBorn': 1967, 'fiscalYear': 2022, 'totalPay': 10655000, 'exercisedValue': 0, 'unexercisedValue': 0}, {'maxAge': 1, 'name': 'Ms. Marianne  Lake', 'age': 53, 'title': 'Chief Executive Officer of Consumer & Community Banking', 'yearBorn': 1970, 'fiscalYear': 2022, 'totalPay': 7520688, 'exercisedValue': 0, 'unexercisedValue': 0}, {'maxAge': 1, 'name': 'Ms. Jennifer A. Piepszak', 'age': 52, 'title': 'Co-Chief Executive Officer of Commercial & Investment Bank', 'yearBorn': 1971, 'fiscalYear': 2022, 'totalPay': 7455000, 'exercisedValue': 0, 'unexercisedValue': 0}, {'maxAge': 1, 'name': 'Ms. Elena A. Korablina', 'age': 49, 'title': 'MD, Firmwide Controller & Principal Accounting Officer', 'yearBorn': 1974, 'fiscalYear': 2022, 'exercisedValue': 0, 'unexercisedValue': 0}, {'maxAge': 1, 'name': 'Mr. Viswas  Raghavan', 'age': 57, 'title': 'Head of Global Investment Banking & CEO of EMEA', 'yearBorn': 1966, 'fiscalYear': 2022, 'exercisedValue': 0, 'unexercisedValue': 0}, {'maxAge': 1, 'name': 'Ms. Lori Ann Beer', 'age': 55, 'title': 'Global Chief Information Officer', 'yearBorn': 1968, 'fiscalYear': 2022, 'exercisedValue': 0, 'unexercisedValue': 0}, {'maxAge': 1, 'name': 'Mr. Mikael  Grubb', 'title': 'Head of Investor Relations', 'fiscalYear': 2022, 'exercisedValue': 0, 'unexercisedValue': 0}], 'auditRisk': 10, 'boardRisk': 6, 'compensationRisk': 7, 'shareHolderRightsRisk': 3, 'overallRisk': 6, 'governanceEpochDate': 1709251200, 'compensationAsOfEpochDate': 1672444800, 'maxAge': 86400, 'priceHint': 2, 'previousClose': 191.38, 'open': 191.03, 'dayLow': 188.67, 'dayHigh': 191.63, 'regularMarketPreviousClose': 191.38, 'regularMarketOpen': 191.03, 'regularMarketDayLow': 188.67, 'regularMarketDayHigh': 191.63, 'dividendRate': 4.2, 'dividendYield': 0.0219, 'exDividendDate': 1704326400, 'payoutRatio': 0.2526, 'fiveYearAvgDividendYield': 2.85, 'beta': 1.127, 'trailingPE': 11.657425, 'forwardPE': 11.671808, 'volume': 3518502, 'regularMarketVolume': 3518502, 'averageVolume': 8914841, 'averageVolume10days': 7026020, 'averageDailyVolume10Day': 7026020, 'bid': 189.18, 'ask': 189.2, 'bidSize': 900, 'askSize': 1100, 'marketCap': 544965984256, 'fiftyTwoWeekLow': 123.11, 'fiftyTwoWeekHigh': 191.73, 'priceToSalesTrailing12Months': 3.7324138, 'fiftyDayAverage': 177.2, 'twoHundredDayAverage': 156.1009, 'trailingAnnualDividendRate': 4.1, 'trailingAnnualDividendYield': 0.021423345, 'currency': 'USD', 'enterpriseValue': -111288500224, 'profitMargins': 0.33938, 'floatShares': 2864356632, 'sharesOutstanding': 2880369920, 'sharesShort': 18812563, 'sharesShortPriorMonth': 17568241, 'sharesShortPreviousMonthDate': 1706659200, 'dateShortInterest': 1709164800, 'sharesPercentSharesOut': 0.0064999997, 'heldPercentInsiders': 0.0091, 'heldPercentInstitutions': 0.7321, 'shortRatio': 2.35, 'shortPercentOfFloat': 0.0066000004, 'impliedSharesOutstanding': 2880369920, 'bookValue': 104.452, 'priceToBook': 1.8113582, 'lastFiscalYearEnd': 1703980800, 'nextFiscalYearEnd': 1735603200, 'mostRecentQuarter': 1703980800, 'earningsQuarterlyGrowth': -0.155, 'netIncomeToCommon': 47759998976, 'trailingEps': 16.23, 'forwardEps': 16.21, 'pegRatio': 10.01, 'lastSplitFactor': '3:2', 'lastSplitDate': 960768000, 'enterpriseToRevenue': -0.762, '52WeekChange': 0.46370935, 'SandP52WeekChange': 0.30427897, 'lastDividendValue': 1.05, 'lastDividendDate': 1704326400, 'exchange': 'NYQ', 'quoteType': 'EQUITY', 'symbol': 'JPM', 'underlyingSymbol': 'JPM', 'shortName': 'JP Morgan Chase & Co.', 'longName': 'JPMorgan Chase & Co.', 'firstTradeDateEpochUtc': 322151400, 'timeZoneFullName': 'America/New_York', 'timeZoneShortName': 'EDT', 'uuid': 'bc753df4-b894-3e19-9c58-995ef66d8e67', 'messageBoardId': 'finmb_658776', 'gmtOffSetMilliseconds': -14400000, 'currentPrice': 189.2, 'targetHighPrice': 238.0, 'targetLowPrice': 157.7, 'targetMeanPrice': 193.14, 'targetMedianPrice': 194.0, 'recommendationMean': 2.1, 'recommendationKey': 'buy', 'numberOfAnalystOpinions': 27, 'totalCash': 1421310033920, 'totalCashPerShare': 493.447, 'totalDebt': 731371995136, 'totalRevenue': 146008997888, 'revenuePerShare': 49.687, 'returnOnAssets': 0.01314, 'returnOnEquity': 0.15979, 'operatingCashflow': 12974000128, 'earningsGrowth': -0.15, 'revenueGrowth': 0.111, 'operatingMargins': 0.36247003, 'financialCurrency': 'USD', 'trailingPegRatio': 3.2927}\n"
     ]
    }
   ],
   "source": [
    "ticker = \"JPM\"\n",
    "\n",
    "stock = yf.Ticker(ticker)\n",
    "\n",
    "print(stock.info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load The data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t1/kp_skn19149_39v2tmch5vqm0000gn/T/ipykernel_76243/2686348765.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n"
     ]
    }
   ],
   "source": [
    "website = 'https://raw.githubusercontent.com/MikeVej/ML_StockPredictor/main/AAPL_historic_prices.csv'\n",
    "df = pd.read_csv(website)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df.head()\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep:\n",
    "---\n",
    "Clean data: handle missing values, standardizing the data for neural network processing, and converting the time series data into a format suitable for training an LSTM model\n",
    "\n",
    "Train, Test, Split: Split date is where the test data starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (966, 10, 2)\n",
      "y_train shape: (966,)\n",
      "X_test shape: (283, 10, 2)\n",
      "y_test shape: (283,)\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "sequence_length = 10  # Use 10 days of historical data to predict the next day price\n",
    "split_date = '2023-01-01'  # Splitting the dataset into training and testing at this date\n",
    "\n",
    "# Selecting the features ('Adj Close' and 'Volume') and the target ('Adj Close')\n",
    "features = df[['Adj Close', 'Volume']]\n",
    "target = df['Adj Close']\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Function to create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:(i + seq_length)]\n",
    "        y = data[i + seq_length, 0]  # Target is the 'Adj Close' price\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Create sequences\n",
    "X, y = create_sequences(scaled_features, sequence_length)\n",
    "\n",
    "# 'Date' column converted to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "\n",
    "# First, find the index where the split should occur\n",
    "split_idx = df[df['Date'] < split_date].shape[0] - sequence_length\n",
    "\n",
    "# Use this index to split the sequenced data\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# Verify the shapes of the split datasets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "# Print the shapes of the datasets to ensure they are not empty\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close1</th>\n",
       "      <th>Volume1</th>\n",
       "      <th>Adj Close2</th>\n",
       "      <th>Volume2</th>\n",
       "      <th>Adj Close3</th>\n",
       "      <th>Volume3</th>\n",
       "      <th>Adj Close4</th>\n",
       "      <th>Volume4</th>\n",
       "      <th>Adj Close5</th>\n",
       "      <th>Volume5</th>\n",
       "      <th>Adj Close6</th>\n",
       "      <th>Volume6</th>\n",
       "      <th>Adj Close7</th>\n",
       "      <th>Volume7</th>\n",
       "      <th>Adj Close8</th>\n",
       "      <th>Volume8</th>\n",
       "      <th>Adj Close9</th>\n",
       "      <th>Volume9</th>\n",
       "      <th>Adj Close10</th>\n",
       "      <th>Volume10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128814</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.199794</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.111689</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.128222</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>0.157643</td>\n",
       "      <td>0.005221</td>\n",
       "      <td>0.109905</td>\n",
       "      <td>0.006051</td>\n",
       "      <td>0.216898</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.220675</td>\n",
       "      <td>0.006204</td>\n",
       "      <td>0.197526</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.212931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.199794</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.111689</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.128222</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>0.157643</td>\n",
       "      <td>0.005221</td>\n",
       "      <td>0.109905</td>\n",
       "      <td>0.006051</td>\n",
       "      <td>0.216898</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.220675</td>\n",
       "      <td>0.006204</td>\n",
       "      <td>0.197526</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.212931</td>\n",
       "      <td>0.007064</td>\n",
       "      <td>0.136414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.111689</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.128222</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>0.157643</td>\n",
       "      <td>0.005221</td>\n",
       "      <td>0.109905</td>\n",
       "      <td>0.006051</td>\n",
       "      <td>0.216898</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.220675</td>\n",
       "      <td>0.006204</td>\n",
       "      <td>0.197526</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.212931</td>\n",
       "      <td>0.007064</td>\n",
       "      <td>0.136414</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>0.147078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.128222</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>0.157643</td>\n",
       "      <td>0.005221</td>\n",
       "      <td>0.109905</td>\n",
       "      <td>0.006051</td>\n",
       "      <td>0.216898</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.220675</td>\n",
       "      <td>0.006204</td>\n",
       "      <td>0.197526</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.212931</td>\n",
       "      <td>0.007064</td>\n",
       "      <td>0.136414</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>0.147078</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.186694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005068</td>\n",
       "      <td>0.157643</td>\n",
       "      <td>0.005221</td>\n",
       "      <td>0.109905</td>\n",
       "      <td>0.006051</td>\n",
       "      <td>0.216898</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.220675</td>\n",
       "      <td>0.006204</td>\n",
       "      <td>0.197526</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.212931</td>\n",
       "      <td>0.007064</td>\n",
       "      <td>0.136414</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>0.147078</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.186694</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.178773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adj Close1   Volume1  Adj Close2   Volume2  Adj Close3   Volume3  \\\n",
       "0    0.000000  0.128814    0.001689  0.199794    0.000200  0.111689   \n",
       "1    0.001689  0.199794    0.000200  0.111689    0.003133  0.128222   \n",
       "2    0.000200  0.111689    0.003133  0.128222    0.005068  0.157643   \n",
       "3    0.003133  0.128222    0.005068  0.157643    0.005221  0.109905   \n",
       "4    0.005068  0.157643    0.005221  0.109905    0.006051  0.216898   \n",
       "\n",
       "   Adj Close4   Volume4  Adj Close5   Volume5  Adj Close6   Volume6  \\\n",
       "0    0.003133  0.128222    0.005068  0.157643    0.005221  0.109905   \n",
       "1    0.005068  0.157643    0.005221  0.109905    0.006051  0.216898   \n",
       "2    0.005221  0.109905    0.006051  0.216898    0.003409  0.220675   \n",
       "3    0.006051  0.216898    0.003409  0.220675    0.006204  0.197526   \n",
       "4    0.003409  0.220675    0.006204  0.197526    0.007556  0.212931   \n",
       "\n",
       "   Adj Close7   Volume7  Adj Close8   Volume8  Adj Close9   Volume9  \\\n",
       "0    0.006051  0.216898    0.003409  0.220675    0.006204  0.197526   \n",
       "1    0.003409  0.220675    0.006204  0.197526    0.007556  0.212931   \n",
       "2    0.006204  0.197526    0.007556  0.212931    0.007064  0.136414   \n",
       "3    0.007556  0.212931    0.007064  0.136414    0.005513  0.147078   \n",
       "4    0.007064  0.136414    0.005513  0.147078    0.002411  0.186694   \n",
       "\n",
       "   Adj Close10  Volume10  \n",
       "0     0.007556  0.212931  \n",
       "1     0.007064  0.136414  \n",
       "2     0.005513  0.147078  \n",
       "3     0.002411  0.186694  \n",
       "4     0.003041  0.178773  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Flatten the sequences\n",
    "X_train_flattened = X_train.reshape(X_train.shape[0], -1)  # This will reshape X_train to (966, 20)\n",
    "\n",
    "# Name columns\n",
    "column_names = []\n",
    "for i in range(1, X_train.shape[1] + 1):  # For each time step\n",
    "    column_names.extend([f'Adj Close{i}', f'Volume{i}'])\n",
    "\n",
    "df_X_train = pd.DataFrame(X_train_flattened, columns=column_names)\n",
    "\n",
    "df_X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create/Define LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "31/31 [==============================] - 2s 17ms/step - loss: 0.1806 - mean_absolute_error: 0.3475 - val_loss: 0.0987 - val_mean_absolute_error: 0.3070\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0261 - mean_absolute_error: 0.1293 - val_loss: 0.0066 - val_mean_absolute_error: 0.0757\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0032 - mean_absolute_error: 0.0437 - val_loss: 0.0048 - val_mean_absolute_error: 0.0558\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0014 - mean_absolute_error: 0.0307 - val_loss: 0.0024 - val_mean_absolute_error: 0.0386\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 9.9408e-04 - mean_absolute_error: 0.0252 - val_loss: 0.0013 - val_mean_absolute_error: 0.0300\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.9323e-04 - mean_absolute_error: 0.0233 - val_loss: 0.0013 - val_mean_absolute_error: 0.0296\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 8.6207e-04 - mean_absolute_error: 0.0225 - val_loss: 0.0012 - val_mean_absolute_error: 0.0289\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.3668e-04 - mean_absolute_error: 0.0223 - val_loss: 0.0012 - val_mean_absolute_error: 0.0272\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 8.1385e-04 - mean_absolute_error: 0.0217 - val_loss: 0.0010 - val_mean_absolute_error: 0.0264\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 7.7937e-04 - mean_absolute_error: 0.0211 - val_loss: 0.0011 - val_mean_absolute_error: 0.0274\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 7.4344e-04 - mean_absolute_error: 0.0204 - val_loss: 9.8775e-04 - val_mean_absolute_error: 0.0259\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 7.2692e-04 - mean_absolute_error: 0.0204 - val_loss: 0.0011 - val_mean_absolute_error: 0.0274\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 7.5687e-04 - mean_absolute_error: 0.0207 - val_loss: 8.6683e-04 - val_mean_absolute_error: 0.0237\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 7.6195e-04 - mean_absolute_error: 0.0206 - val_loss: 9.3669e-04 - val_mean_absolute_error: 0.0254\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 6.8522e-04 - mean_absolute_error: 0.0196 - val_loss: 8.5444e-04 - val_mean_absolute_error: 0.0239\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 6.7120e-04 - mean_absolute_error: 0.0194 - val_loss: 8.0746e-04 - val_mean_absolute_error: 0.0231\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 6.9447e-04 - mean_absolute_error: 0.0197 - val_loss: 8.5789e-04 - val_mean_absolute_error: 0.0243\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 6.4550e-04 - mean_absolute_error: 0.0190 - val_loss: 8.8116e-04 - val_mean_absolute_error: 0.0248\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 6.5891e-04 - mean_absolute_error: 0.0190 - val_loss: 0.0016 - val_mean_absolute_error: 0.0343\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 6.5472e-04 - mean_absolute_error: 0.0191 - val_loss: 8.9169e-04 - val_mean_absolute_error: 0.0250\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 6.4135e-04 - mean_absolute_error: 0.0189 - val_loss: 7.1387e-04 - val_mean_absolute_error: 0.0217\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 6.2462e-04 - mean_absolute_error: 0.0187 - val_loss: 7.3993e-04 - val_mean_absolute_error: 0.0212\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 6.0794e-04 - mean_absolute_error: 0.0184 - val_loss: 8.3219e-04 - val_mean_absolute_error: 0.0241\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 6.0316e-04 - mean_absolute_error: 0.0183 - val_loss: 7.8433e-04 - val_mean_absolute_error: 0.0233\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 5.8975e-04 - mean_absolute_error: 0.0179 - val_loss: 6.5869e-04 - val_mean_absolute_error: 0.0201\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 6.0929e-04 - mean_absolute_error: 0.0183 - val_loss: 6.0735e-04 - val_mean_absolute_error: 0.0199\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 6.1536e-04 - mean_absolute_error: 0.0186 - val_loss: 6.6425e-04 - val_mean_absolute_error: 0.0212\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 5.8185e-04 - mean_absolute_error: 0.0179 - val_loss: 7.0983e-04 - val_mean_absolute_error: 0.0222\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 5.5100e-04 - mean_absolute_error: 0.0175 - val_loss: 5.5412e-04 - val_mean_absolute_error: 0.0189\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 5.4225e-04 - mean_absolute_error: 0.0173 - val_loss: 6.8821e-04 - val_mean_absolute_error: 0.0218\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 5.2169e-04 - mean_absolute_error: 0.0170 - val_loss: 5.3909e-04 - val_mean_absolute_error: 0.0188\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 5.0164e-04 - mean_absolute_error: 0.0166 - val_loss: 5.1416e-04 - val_mean_absolute_error: 0.0178\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 5.2922e-04 - mean_absolute_error: 0.0171 - val_loss: 4.7288e-04 - val_mean_absolute_error: 0.0173\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 5.0123e-04 - mean_absolute_error: 0.0166 - val_loss: 4.6044e-04 - val_mean_absolute_error: 0.0171\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 5.8225e-04 - mean_absolute_error: 0.0181 - val_loss: 4.5119e-04 - val_mean_absolute_error: 0.0169\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 5.2040e-04 - mean_absolute_error: 0.0169 - val_loss: 5.2117e-04 - val_mean_absolute_error: 0.0186\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 4.6361e-04 - mean_absolute_error: 0.0158 - val_loss: 4.8715e-04 - val_mean_absolute_error: 0.0172\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 4.8510e-04 - mean_absolute_error: 0.0162 - val_loss: 4.7292e-04 - val_mean_absolute_error: 0.0170\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 4.6182e-04 - mean_absolute_error: 0.0159 - val_loss: 4.1189e-04 - val_mean_absolute_error: 0.0161\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 4.4772e-04 - mean_absolute_error: 0.0156 - val_loss: 3.9269e-04 - val_mean_absolute_error: 0.0158\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 4.6214e-04 - mean_absolute_error: 0.0158 - val_loss: 4.0061e-04 - val_mean_absolute_error: 0.0161\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 4.4983e-04 - mean_absolute_error: 0.0156 - val_loss: 3.7822e-04 - val_mean_absolute_error: 0.0156\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 4.4295e-04 - mean_absolute_error: 0.0153 - val_loss: 3.7943e-04 - val_mean_absolute_error: 0.0156\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 4.0824e-04 - mean_absolute_error: 0.0149 - val_loss: 3.6373e-04 - val_mean_absolute_error: 0.0153\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 4.6805e-04 - mean_absolute_error: 0.0161 - val_loss: 4.3177e-04 - val_mean_absolute_error: 0.0161\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 4.0909e-04 - mean_absolute_error: 0.0148 - val_loss: 3.7232e-04 - val_mean_absolute_error: 0.0154\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 4.1593e-04 - mean_absolute_error: 0.0150 - val_loss: 7.0265e-04 - val_mean_absolute_error: 0.0222\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 4.2055e-04 - mean_absolute_error: 0.0150 - val_loss: 8.2554e-04 - val_mean_absolute_error: 0.0245\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 3.9874e-04 - mean_absolute_error: 0.0146 - val_loss: 4.0563e-04 - val_mean_absolute_error: 0.0162\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 4.0121e-04 - mean_absolute_error: 0.0147 - val_loss: 4.2409e-04 - val_mean_absolute_error: 0.0166\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Assuming your predictions are for 'Adj Close' and you initially scaled 'Adj Close' and 'Volume'\n",
    "dummy_feature = np.zeros((predictions.shape[0], 1))  # Create a column of zeros for the dummy feature\n",
    "\n",
    "# Concatenate your predictions with the dummy feature to match the original feature shape\n",
    "predictions_with_dummy = np.hstack([predictions, dummy_feature])\n",
    "\n",
    "# Apply the inverse transformation\n",
    "predictions_inverse = scaler.inverse_transform(predictions_with_dummy)[:, 0]  # Select only the 'Adj Close' predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0691\n",
      "MAE : 0.0277\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(np.mean(history.history['loss']))\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "\n",
    "mae = np.mean(history.history['mean_absolute_error'])\n",
    "print(f'MAE : {mae:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error in Dollars ($)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_feature = np.zeros(predictions.shape)  # Create a dummy array with zeros\n",
    "\n",
    "# Stack your predictions and the dummy feature to match the original shape\n",
    "predictions_with_dummy = np.hstack([predictions, dummy_feature])\n",
    "\n",
    "# Inversely transform and then select only the column with the predictions\n",
    "predictions_inverse = scaler.inverse_transform(predictions_with_dummy)[:, 0]\n",
    "\n",
    "# Repeat similar steps for y_test if needed\n",
    "y_test_with_dummy = np.hstack([y_test.reshape(-1, 1), dummy_feature])\n",
    "y_test_inverse = scaler.inverse_transform(y_test_with_dummy)[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on original scale.  : $3.23\n"
     ]
    }
   ],
   "source": [
    "# Recalculate RMSE on the original scale\n",
    "rmse_original = np.sqrt(mean_squared_error(y_test_inverse, predictions_inverse))\n",
    "print(f'RMSE on original scale.  : ${rmse_original:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
